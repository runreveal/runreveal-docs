---
title: 'Dashboard Graphs Guide'
description: 'Complete guide to creating and configuring dashboard graphs in RunReveal with SQL examples, best practices, and configuration options.'
---

import { Callout } from 'nextra/components'

# Dashboard Graphs Guide

RunReveal's dashboard system allows you to create custom visualizations of your security and infrastructure data using SQL queries against ClickHouse tables. This guide covers everything you need to know to build effective dashboards.

## Overview

Dashboard graphs in RunReveal consist of three main components:

- **Graphs**: SQL queries that define the data and visualization type
- **Panels**: Containers that display graphs with specific sizing and positioning
- **Layouts**: Dashboard arrangements that organize multiple panels

## Graph Configuration

### Graph Properties

Each graph has the following configurable properties:

| Property | Type | Description | Example |
|----------|------|-------------|---------|
| `name` | string | Unique identifier (slug format) | `failed-logins` |
| `displayName` | string | Human-readable title | `Failed Login Attempts` |
| `query` | string | SQL query for data | `SELECT ... FROM okta_logs` |
| `type` | string | Chart visualization type | `line`, `bar`, `pie`, `area` |
| `xAxisColumnName` | string | Column for X-axis | `hour`, `country`, `user` |
| `yAxisColumnName` | string | Column for Y-axis | `count`, `events`, `users` |
| `xTitle` | string | X-axis label | `Time`, `Country`, `User` |
| `yTitle` | string | Y-axis label | `Count`, `Events`, `Users` |
| `fill` | boolean | Fill area under line/bar | `true`, `false` |
| `stack` | string | Stacking behavior | `default`, `stacked`, `stacked100`, `unstacked` |
| `stackColumn` | string | Column to stack by | `severity`, `source`, `type` |

### Chart Types

#### Line Charts
Best for time series data showing trends over time.

```sql
SELECT 
    toStartOfHour(eventTime) as hour,
    count() as events
FROM logs 
WHERE eventTime >= now() - INTERVAL 24 HOUR
GROUP BY hour
ORDER BY hour
```

#### Bar Charts
Ideal for categorical data comparisons.

```sql
SELECT 
    srcASCountryCode as country,
    count() as events
FROM logs 
WHERE eventTime >= now() - INTERVAL 24 HOUR
    AND srcASCountryCode != ''
GROUP BY country
ORDER BY events DESC
LIMIT 10
```

#### Pie Charts
Perfect for showing proportional data.

```sql
SELECT 
    eventName,
    count() as count
FROM google_workspace_logs 
WHERE eventTime >= now() - INTERVAL 7 DAY
GROUP BY eventName
ORDER BY count DESC
LIMIT 8
```

#### Area Charts
Similar to line charts but with filled areas.

```sql
SELECT 
    toStartOfDay(eventTime) as day,
    count() as daily_events
FROM logs 
WHERE eventTime >= now() - INTERVAL 30 DAY
GROUP BY day
ORDER BY day
```

### Stacking Options

#### Default (No Stacking)
```json
{
  "stack": "default"
}
```

#### Stacked
```json
{
  "stack": "stacked",
  "stackColumn": "severity"
}
```

#### 100% Stacked
```json
{
  "stack": "stacked100",
  "stackColumn": "sourceType"
}
```

#### Unstacked
```json
{
  "stack": "unstacked"
}
```

## Available Data Sources

### Security & Authentication Logs

<Callout type="info">
All tables support time-based filtering using `eventTime >= now() - INTERVAL X DAY/HOUR`
</Callout>

#### Core Security Tables
- `logs` - General log events from all sources
- `aws_cloudtrail_logs` - AWS CloudTrail API events
- `aws_guardduty_logs` - AWS GuardDuty security findings
- `okta_logs` - Okta authentication and authorization events
- `auth0_logs` - Auth0 authentication events
- `entra_logs` - Microsoft Entra ID (Azure AD) logs
- `google_workspace_logs` - Google Workspace admin and user events
- `github_logs` - GitHub audit and security events
- `gitlab_logs` - GitLab audit events

#### Identity & Access Management
- `jumpcloud_directory_logs` - JumpCloud directory events
- `duo_logs` - Duo Security authentication logs
- `teleport_audit_logs` - Teleport access logs
- `lumos_logs` - Lumos access management events

### Network & Infrastructure

#### Network Monitoring
- `flow_logs` - Network flow data
- `nsg_flow_logs` - Azure Network Security Group flows
- `azure_flow_logs` - Azure network flow logs
- `aws_dns_logs` - AWS DNS query logs
- `aws_hosted_zone_logs` - AWS Route53 logs

#### Cloudflare Logs
- `cf_audit_logs` - Cloudflare audit events
- `cf_firewall_logs` - Cloudflare firewall events
- `cf_http_logs` - Cloudflare HTTP request logs
- `cf_gateway_dns_logs` - Cloudflare Gateway DNS logs
- `cf_gateway_http_logs` - Cloudflare Gateway HTTP logs
- `cf_gateway_network_logs` - Cloudflare Gateway network logs
- `cf_access_requests_logs` - Cloudflare Access requests

### Application & Service Logs

#### Development & CI/CD
- `kubernetes_audit_logs` - Kubernetes API audit events
- `circleci_audit_logs` - CircleCI build and deployment logs
- `heroku_logs` - Heroku application logs

#### Business Applications
- `slack_logs` - Slack audit and activity logs
- `notion_logs` - Notion workspace activity
- `atlassian_logs` - Atlassian product logs (Jira, Confluence)
- `pagerduty_logs` - PagerDuty incident logs
- `zendesk_logs` - Zendesk ticket and activity logs

### Security Tools

#### Endpoint Detection & Response
- `crowdstrike_aidmaster_logs` - CrowdStrike AID master logs
- `crowdstrike_managed_logs` - CrowdStrike managed logs
- `crowdstrike_data_logs` - CrowdStrike data logs
- `sentinelone_activity_logs` - SentinelOne activity logs
- `sentinelone_threat_logs` - SentinelOne threat logs

#### Security Monitoring
- `sophos_alert_logs` - Sophos security alerts
- `sophos_event_logs` - Sophos security events
- `wiz_threat_webhook_logs` - Wiz threat intelligence
- `wiz_issue_webhook_logs` - Wiz security issues
- `abnormal_logs` - Abnormal Security events

### RunReveal System Tables

#### Detection & Alerting
- `alerts` - Security detection alerts
- `signals` - Security signals and findings
- `detections` - Detection rule results
- `signals_grouped` - Grouped security signals

#### System Monitoring
- `runreveal_audit_logs` - RunReveal system audit logs
- `runreveal_source_volumes` - Data source volume metrics
- `usage_events` - Usage tracking events
- `external_metrics` - Custom metrics and KPIs

## SQL Query Examples

### Authentication & Access Control

#### Failed Login Attempts Over Time
```sql
SELECT 
    toStartOfHour(eventTime) as hour,
    count() as failed_logins
FROM okta_logs 
WHERE eventType = 'user.session.start' 
    AND outcome.result = 'FAILURE'
    AND eventTime >= now() - INTERVAL 7 DAY
GROUP BY hour
ORDER BY hour
```

#### Top Source Countries for Logins
```sql
SELECT 
    srcASCountryCode as country,
    count() as login_attempts,
    countDistinct(actor.email) as unique_users
FROM okta_logs 
WHERE eventType = 'user.session.start'
    AND eventTime >= now() - INTERVAL 24 HOUR
    AND srcASCountryCode != ''
GROUP BY country
ORDER BY login_attempts DESC
LIMIT 15
```

#### Privilege Escalation Events
```sql
SELECT 
    eventTime,
    actor.email as assigned_by,
    JSONExtractString(rawLog, 'events', 0, 'parameters', 1, 'value') as user_email,
    JSONExtractString(rawLog, 'events', 0, 'parameters', 0, 'value') as role_name
FROM google_workspace_logs 
WHERE eventName IN ('ASSIGN_ROLE', 'UNASSIGN_ROLE')
    AND eventTime >= now() - INTERVAL 30 DAY
ORDER BY eventTime DESC
```

### Network Security

#### Top Destination IPs by Traffic Volume
```sql
SELECT 
    dstIP,
    count() as connection_count,
    sum(bytes) as total_bytes
FROM flow_logs 
WHERE eventTime >= now() - INTERVAL 1 HOUR
    AND dstIP != ''
GROUP BY dstIP
ORDER BY total_bytes DESC
LIMIT 20
```

#### Geographic Distribution of Network Events
```sql
SELECT 
    srcASCountryCode as country,
    count() as events,
    countDistinct(srcIP) as unique_ips,
    countDistinct(actor.email) as unique_users
FROM logs 
WHERE eventTime >= now() - INTERVAL 24 HOUR
    AND srcASCountryCode != ''
GROUP BY country
ORDER BY events DESC
LIMIT 15
```

#### Cloudflare Security Events
```sql
SELECT 
    toStartOfHour(timestamp) as hour,
    action,
    count() as events
FROM cf_firewall_logs 
WHERE timestamp >= now() - INTERVAL 24 HOUR
    AND action IN ('block', 'challenge', 'log')
GROUP BY hour, action
ORDER BY hour, action
```

### User Activity & Behavior

#### Active Users by Hour
```sql
SELECT 
    toStartOfHour(eventTime) as hour,
    countDistinct(actor.email) as active_users
FROM logs 
WHERE eventTime >= now() - INTERVAL 24 HOUR
    AND actor.email != ''
GROUP BY hour
ORDER BY hour
```

#### Top Applications by Usage
```sql
SELECT 
    serviceName,
    count() as events,
    countDistinct(actor.email) as unique_users
FROM google_workspace_logs 
WHERE eventTime >= now() - INTERVAL 7 DAY
    AND serviceName != ''
GROUP BY serviceName
ORDER BY events DESC
LIMIT 10
```

#### Suspicious Login Patterns
```sql
SELECT 
    actor.email,
    srcASCountryCode,
    count() as login_count,
    min(eventTime) as first_seen,
    max(eventTime) as last_seen
FROM okta_logs 
WHERE eventType = 'user.session.start'
    AND outcome.result = 'SUCCESS'
    AND eventTime >= now() - INTERVAL 30 DAY
GROUP BY actor.email, srcASCountryCode
HAVING login_count > 5
ORDER BY login_count DESC
```

### Data Security & Compliance

#### Data Exfiltration Indicators
```sql
SELECT 
    eventTime,
    actor.email,
    srcIP,
    JSONExtractString(rawLog, 'events', 0, 'name') as action,
    JSONExtractString(rawLog, 'events', 0, 'parameters', 0, 'value') as file_name
FROM google_workspace_logs 
WHERE eventName = 'DOWNLOAD'
    AND eventTime >= now() - INTERVAL 7 DAY
ORDER BY eventTime DESC
```

#### File Sharing Events
```sql
SELECT 
    toStartOfDay(eventTime) as day,
    JSONExtractString(rawLog, 'events', 0, 'name') as share_action,
    count() as events
FROM google_workspace_logs 
WHERE eventName LIKE '%SHARE%'
    AND eventTime >= now() - INTERVAL 30 DAY
GROUP BY day, share_action
ORDER BY day, events DESC
```

### System Health & Monitoring

#### Source Health and Volume
```sql
SELECT 
    sourceID,
    sourceType,
    count() as event_count,
    min(eventTime) as earliest_event,
    max(eventTime) as latest_event
FROM logs 
WHERE eventTime >= now() - INTERVAL 24 HOUR
GROUP BY sourceID, sourceType
ORDER BY event_count DESC
```

#### Alert Trends by Severity
```sql
SELECT 
    toStartOfHour(createdAt) as hour,
    severity,
    count() as alert_count
FROM alerts 
WHERE createdAt >= now() - INTERVAL 7 DAY
GROUP BY hour, severity
ORDER BY hour, severity
```

#### Detection Rule Performance
```sql
SELECT 
    detectionName,
    count() as triggers,
    countDistinct(actor.email) as affected_users,
    avg(riskScore) as avg_risk_score
FROM detections 
WHERE createdAt >= now() - INTERVAL 7 DAY
GROUP BY detectionName
ORDER BY triggers DESC
LIMIT 20
```

## Panel Configuration

### Panel Sizes

Panels support the following width options:

| Size | Description | Use Case |
|------|-------------|----------|
| `xxs` | Extra extra small | Single metric displays |
| `xs` | Extra small | Simple charts |
| `sm` | Small | Basic time series |
| `md` | Medium | Standard charts |
| `lg` | Large | Complex visualizations |
| `xl` | Extra large | Full-width dashboards |

### Panel Properties

```json
{
  "id": "panel-1",
  "graphId": "failed-logins-graph",
  "width": "lg",
  "title": "Failed Login Attempts",
  "position": 1
}
```

## Best Practices

### Query Optimization

#### Time-Based Filtering
Always include time-based filtering to improve performance:

```sql
-- Good: Time-filtered query
SELECT toStartOfHour(eventTime) as hour, count() as events
FROM logs 
WHERE eventTime >= now() - INTERVAL 7 DAY
GROUP BY hour
ORDER BY hour

-- Bad: No time filtering
SELECT toStartOfHour(eventTime) as hour, count() as events
FROM logs 
GROUP BY hour
ORDER BY hour
```

#### Appropriate Aggregation
Use the right aggregation functions for your data:

```sql
-- Count events
SELECT count() as total_events

-- Count unique values
SELECT countDistinct(actor.email) as unique_users

-- Sum numeric values
SELECT sum(bytes) as total_bytes

-- Average values
SELECT avg(responseTime) as avg_response_time
```

#### Result Limiting
Limit results for large datasets:

```sql
-- Limit top results
SELECT country, count() as events
FROM logs 
GROUP BY country
ORDER BY events DESC
LIMIT 20
```

### Column Naming

Use descriptive column names that work well in graphs:

```sql
-- Good: Descriptive names
SELECT 
    toStartOfHour(eventTime) as hour,
    count() as failed_logins,
    countDistinct(actor.email) as unique_users

-- Bad: Generic names
SELECT 
    toStartOfHour(eventTime) as time,
    count() as count,
    countDistinct(actor.email) as distinct
```

### Graph Type Selection

Choose the right chart type for your data:

- **Line Charts**: Time series data, trends over time
- **Bar Charts**: Categorical comparisons, rankings
- **Pie Charts**: Proportional data, parts of a whole
- **Area Charts**: Cumulative data, filled time series

### Performance Considerations

#### Query Complexity
Keep queries simple and focused:

```sql
-- Good: Simple, focused query
SELECT toStartOfHour(eventTime) as hour, count() as events
FROM logs 
WHERE eventTime >= now() - INTERVAL 24 HOUR
GROUP BY hour
ORDER BY hour

-- Avoid: Overly complex queries with many joins
SELECT /* complex query with multiple joins */
```

#### Data Volume
Consider data volume when designing queries:

- Use appropriate time ranges (1 hour, 24 hours, 7 days, 30 days)
- Limit result sets with `LIMIT` clauses
- Use aggregation to reduce data points

## API Reference

### Graph Management Endpoints

#### Create Graph
```bash
POST /api/dashboard/graph/create
Content-Type: application/json

{
  "name": "failed-logins",
  "displayName": "Failed Login Attempts",
  "query": "SELECT toStartOfHour(eventTime) as hour, count() as failed_logins FROM okta_logs WHERE eventType = 'user.session.start' AND outcome.result = 'FAILURE' AND eventTime >= now() - INTERVAL 7 DAY GROUP BY hour ORDER BY hour",
  "type": "line",
  "xAxisColumnName": "hour",
  "yAxisColumnName": "failed_logins",
  "xTitle": "Time",
  "yTitle": "Failed Logins",
  "fill": true,
  "stack": "default"
}
```

#### List Graphs
```bash
GET /api/dashboard/graph/list
```

#### Update Graph
```bash
POST /api/dashboard/graph/update
Content-Type: application/json

{
  "id": "graph-id",
  "query": "updated SQL query",
  "displayName": "Updated Display Name"
}
```

#### Delete Graph
```bash
POST /api/dashboard/graph/delete
Content-Type: application/json

{
  "id": "graph-id"
}
```

### Layout Management Endpoints

#### Create Layout
```bash
POST /api/dashboard/layout/create
Content-Type: application/json

{
  "name": "security-overview",
  "displayName": "Security Overview Dashboard"
}
```

#### Update Layout
```bash
POST /api/dashboard/layout/update
Content-Type: application/json

{
  "id": "layout-id",
  "panels": [
    {
      "id": "panel-1",
      "graphId": "graph-id",
      "width": "lg",
      "title": "Failed Logins",
      "position": 1
    }
  ]
}
```

## Troubleshooting

### Common Issues

#### No Data in Graph
- Check if the time range includes data
- Verify table names and column names
- Ensure proper WHERE clause filtering

#### Slow Query Performance
- Add time-based filtering
- Use appropriate aggregation
- Limit result sets
- Check for missing indexes

#### Graph Not Displaying
- Verify column names match configuration
- Check data types (numeric for Y-axis)
- Ensure query returns results

#### Incorrect Data
- Validate SQL query logic
- Check time zone handling
- Verify aggregation functions

### Debugging Tips

1. **Test Queries First**: Use the query interface to test SQL before creating graphs
2. **Check Column Types**: Ensure X-axis and Y-axis columns have correct data types
3. **Validate Time Ranges**: Make sure your time filtering includes the expected data
4. **Monitor Performance**: Watch for slow queries and optimize as needed

## Example Dashboard Configurations

### Security Overview Dashboard

```json
{
  "name": "security-overview",
  "displayName": "Security Overview",
  "panels": [
    {
      "id": "failed-logins",
      "graphId": "failed-logins-graph",
      "width": "lg",
      "title": "Failed Login Attempts",
      "position": 1
    },
    {
      "id": "top-countries",
      "graphId": "top-countries-graph", 
      "width": "md",
      "title": "Top Source Countries",
      "position": 2
    },
    {
      "id": "alert-trends",
      "graphId": "alert-trends-graph",
      "width": "lg", 
      "title": "Alert Trends",
      "position": 3
    }
  ]
}
```

### User Activity Dashboard

```json
{
  "name": "user-activity",
  "displayName": "User Activity Dashboard",
  "panels": [
    {
      "id": "active-users",
      "graphId": "active-users-graph",
      "width": "md",
      "title": "Active Users Over Time",
      "position": 1
    },
    {
      "id": "top-apps",
      "graphId": "top-apps-graph",
      "width": "md",
      "title": "Top Applications",
      "position": 2
    },
    {
      "id": "user-geography",
      "graphId": "user-geography-graph",
      "width": "lg",
      "title": "User Geographic Distribution",
      "position": 3
    }
  ]
}
```

This comprehensive guide provides everything you need to create effective dashboard graphs in RunReveal, from basic configuration to advanced query optimization and troubleshooting.---
title: 'Dashboards'
description: 'Create and manage dashboards to visualize your security data and gain insights into your environment.'
---

# Dashboards

Create and manage dashboards to visualize your security data and gain insights into your environment.

## Overview

Dashboards in RunReveal allow you to create custom visualizations of your security data, helping you monitor threats, track trends, and gain actionable insights.

## Getting Started

Coming soon - documentation for creating and managing dashboards will be available here.

## Features

- Custom dashboard creation
- Real-time data visualization
- Interactive charts and graphs
- Dashboard sharing and collaboration
- Pre-built dashboard templates

## Need Help?

If you have questions about dashboards, please contact our support team through:

- Our [Discord community](https://discord.gg/n3y6WwPCg7)
- Email at contact@runreveal.com
- The chat bubble on our website
