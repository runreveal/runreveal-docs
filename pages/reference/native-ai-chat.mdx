import { Callout } from 'nextra/components'

<style jsx>{`
  img {
    border-radius: 5px;
  }
`}</style>

# Native AI Chat

RunReveal's Native AI Chat is a purpose-built investigation agent that lets you analyze your security data conversationally, directly inside the RunReveal console. It executes complex queries, analyzes patterns, and guides you through investigations—all without your data ever leaving the platform.

![Native AI Chat Overview](/native-ai-chat-1.png)


## What is Native AI Chat?

Native AI Chat is fully integrated into the RunReveal UI, giving you a secure, auditable, and persistent way to investigate logs and detections using natural language. Unlike external chat clients, Native AI Chat runs entirely within your workspace, leveraging your own API keys for model access.

## Why Native AI Chat?

- **Direct data access**: Query logs, examine table schemas, and analyze security data in real-time using the same APIs that you already use.
- **Transparent reasoning**: Every action is explained and auditable. See exactly why a query was run or a tool was used.
- **Persistent context**: The chat remembers your investigation history, enabling complex, multi-day investigations.
- **Secure by design**: Your data never leaves the RunReveal platform. All model calls are made server-side, using your own API keys.

## What Can You Do with Native AI Chat?

### Investigation Examples
- "Show me all failed login attempts from the last 24 hours"
- "Find privilege escalation events in the past week"
- "What IP addresses had the most failed authentication attempts?"

### Detection Analysis
- "List all detection rules for brute force attacks"
- "Show me which detections fired most frequently this week"
- "What detection rules do we have for privilege escalation?"

### Data Exploration
- "What tables contain network traffic data?"
- "Show me the schema for the authentication logs"
- "Find all unique user agents in web traffic logs"

## Common Use Cases

### Incident Response
"I need to investigate a suspicious login from IP 192.168.1.100"
→ Agent analyzes login patterns, cross-references with threat intel, suggests next steps

### Security Monitoring
"Show me our top security events this week"
→ Agent queries multiple log sources, creates summary with actionable insights

### Data Analysis
"Analyze authentication events from the past 30 days by geographic location, show me login attempts by country and city"
→ Agent reviews existing data, identifies trends, provides insights 

---

## Supported Model Providers

Native AI Chat supports multiple LLM providers. Workspace admins can add API keys for any or all of the following:

- [Anthropic (Claude)](https://docs.anthropic.com/en/api/overview)  
- [OpenAI (ChatGPT)](https://platform.openai.com/account/api-keys)  
- [Google AI (Gemini)](https://ai.google.dev/gemini-api/docs/api-key)

Each model runs securely and never leaves the RunReveal platform.

<Callout type="info">
Admins can now configure multiple providers and set a default provider for the workspace. When starting a new chat, users can select from any configured provider. Once a provider is selected for a chat session, it is fixed for that session, but you can start a new chat with a different provider at any time.
</Callout>

---

## Setup Guide: Native AI Chat

### Prerequisites

- A RunReveal account with admin or API access
- API key(s) for your preferred LLM provider(s): [Anthropic (Claude)](https://docs.anthropic.com/en/api/overview), [OpenAI (ChatGPT)](https://platform.openai.com/account/api-keys), or [Google AI (Gemini)](https://ai.google.dev/gemini-api/docs/api-key)
- Access to your RunReveal workspace settings

### Step 1: Open AI Model Providers Settings

1. In the RunReveal UI, go to **Workspace Settings → AI Model Providers**

![Native AI Chat Settings](/native-ai-chat-setup-1.png)

### Step 2: Add Your LLM API Keys

1. Add API keys for any providers you want to enable (Anthropic, OpenAI, or Google AI).
2. You can add multiple providers; you do **not** need to remove unused keys.

### Step 3: Set a Default Provider (Admin Only)

1. In the provider settings, select which provider should be the default for your workspace.
2. This provider will be pre-selected for new chat sessions, but users can change it.

![LLM dropdown](/native-ai-chat-dropdown.png)

### Step 4: Start Chatting and Select Provider

1. When starting a new chat, you’ll see a dropdown to select from any configured provider.
2. Once you select a provider/model, it will be used for the duration of that chat session.
3. To use a different provider, simply start a new chat and select a different provider.

## Usage

Once set up, you can ask:
- "Show me all failed login attempts from the last 24 hours"
- "What detection rules do we have for privilege escalation?"
- "Create a new detection for suspicious file downloads"
- "What tables contain network traffic data?"

### Native AI Chat responding to investigation prompt:

<iframe
  src="https://customer-c44ap1ntg00ikdh2.cloudflarestream.com/d01cf154e8cc8e1012246ffa5130c428/iframe?autoplay=true&muted=true&loop=true&controls=false&speed=1.3"
  style={{ width: '100%', aspectRatio: '16/9', border: 'none', borderRadius: '8px' }}
  allow="autoplay; encrypted-media; picture-in-picture"
  loading="lazy"
/>

### How the agent reorients after a failed query:

<iframe
  src="https://customer-c44ap1ntg00ikdh2.cloudflarestream.com/f88b13fbaae8bb629f1a6a3609b3eef3/iframe?autoplay=true&muted=true&loop=true&controls=false&speed=1.3"
  style={{ width: '100%', aspectRatio: '16/9', border: 'none', borderRadius: '8px' }}
  allow="autoplay; encrypted-media; picture-in-picture"
  loading="lazy"
/>

## How It Works: The Investigation Process

Native AI Chat uses a structured approach to investigations:

**Example**: "Investigate failed logins from suspicious IPs"

1. **Observe**: "Let me check your authentication logs and IP reputation data"
2. **Orient**: "I found 50 failed logins from 3 high-risk IPs in the last hour"
3. **Decide**: "I should cross-reference these with your user directory and check for successful logins"
4. **Act**: Queries user tables, generates timeline, suggests blocking actions


## Getting the Most from Native AI Chat

### Effective Prompts
- Be specific about timeframes: "last 24 hours" vs "recently"
- Include context: "high-priority alerts" vs "all alerts"
- Ask follow-up questions: "What caused this spike in DNS queries?"

### Investigation Tips
- Start broad, then narrow down: "Show me authentication events" → "Focus on failed logins"
- Ask for explanations: "Why did this detection fire?"
- Request recommendations: "What should I investigate next?"
